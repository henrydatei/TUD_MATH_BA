\chapter{Introduction}
\section{The central issue of financial mathematics}
\subsection*{\begriff{Valuation}:}
Valuation of derivatives and \emph{hedge} against the risks which emerges from the purchase / sale,

\begin{*definition}[\begriff{Derivative}]
	Financial product whose payouts are derived from price of one or more \begriff{basic goods} derived (underlying) derivative.
\end{*definition}
\begin{*example}
	\begin{itemize}
		\item Right to get 100,000 GBP in 3 months against 125,000 EUR (\begriff{Call-Option}, Underlying: Exchange rate GBP/EUR)
		\item Right within the next year to consume 100,000 Mw / h of electric energy at the price of 30EUR/Mwh with minimum order quantity of 50,000 Mwh (\begriff{Swing-Option}, Underlying: electricity price)
		\item buying and selling options on stock (Underlying: equity price)
	\end{itemize}
\end{*example}
Issue:  What is the ''fair'' price for such a derivative? (``Pricing''). How can the sellers protect themselves against the … risks? (``Hedging'')

\subsection*{\begriff{Optimal investment}}
Gathering Porftolios that are optimal for risk-return approach.
\begin{itemize}
	\item How do I weigh risk against profit?
	\item What exactly is ''optimal''?
	\item Solution of the resulting optimization problems
\end{itemize}
\subsection*{\begriff{Risk management + Risk measurement}}
\begin{itemize}
	
	\item Legal rules (Basel + Solvency) should ensure stability of the banking system/insurance system even in the face of various risks 
	
	$\implies$ Mathematical theory of convex + coherent risk measures 
\end{itemize}	 
Mathematical tools: Probability Theory + stochastic processes (dynamics in time, some linear algebra, optimization, measure theory).

\section{Mathematical Financial Market Model}
We consider:
\begin{enumerate}
	\item \emph{Probability space} $(\O,\F,\P)$, later more probability measures $Q, \dots$ on the same measure space $(\O,\F), \omega \in \O$ basic events or ''scenarios''.
	\item \emph{Timeline} $I$ is either $I=\set{t_0, t_1, \dots, t_N=T}$ $N$-period model (discrete model) or $I = [0,T]$ (continious-time model), where $T = $ time-horizon\\
	A \begriff{stochastic process} $S$ is a measurable mapping $S: (\O,\F) \to \R^d \mit (\omega, t) \mapsto S_t(\omega)$\\
	Especially:
	\begin{itemize}
		\item $t \mapsto S_t(\omega)$ function $I \to \R^d$ for every $\omega \in \O$ (``path'')
		\item $\omega \mapsto S_t(\omega)$ random variable $\O \to \R^d$ for every $t \in I$
	\end{itemize}
	\item \emph{Percolation} 
	a sequence of $\omega$-algebras $(F_t)_{t \in I}$ with the property $\F_S \subseteq F_t \quad \forall s,t \in I, x \le t$ and $F_t \subseteq F\quad \forall t \in I$\\
	Interpretation: $F_t=$ market participant at time $t$ known/available information\\
	Events $A \in F_t$ are considered known 'at time t'\\
	A $R^d$-valued RV $X$ is called  \begriff{$F_t$-measurable}, if $E = X^{-1}(B) \in F_t \quad \forall$ Borel sets $B \subseteq R^d$ ($E$ is actually the preimage of $B$).
	
	\begin{*example}
		A stochastic process  $(S_t)_{t\in I}$ on $(\O,\F)$ is called \begriff[stochastic process]{adaptiert} regarding a percolation $(\F_t)_{t \in I}$, wenn gilt:
		\begin{align*}
			S_t \text{ is } F_t-\text{measurable} \quad \forall t \in I
		\end{align*}
	\end{*example}
	Interpretation: ``the value $S_t$ is known at time $t$''\\
	Why percolation in the financial mathematics (FiMa)?
	\begin{itemize}
		\item Differentiation between future/past
		\item Different information (Insider/Outsider) corresponds to different percolation $(F_t)_{t \in I}$ or $(G_t)_{t\in I}$
	\end{itemize}
	$S^i$= price of the i-th asset at the time t
	\item \begriff{Assets} $R^{d+1}$-valued  stochastic process with components
	\begin{align*}
		S^i: (\O \times I) \to \R\quad (\omega,t) \mapsto S^i_t(\omega) \mit i \in \set{0,1,\dots,d}
	\end{align*} 
	where $S^i_t=$ price of the $i$-th asset at time $t$\\
	$S^i, i \in \set{1,\dots,d}$ is typically
	\begin{itemize}
		\item Stock, company share
		\item Currency or exchange rate
		\item Commodity such as oil, noble metal, electricity,..
		\item Bond ... 
	\end{itemize}
	Principal assumption: $S^i$ is liquid traded (eg on exchange), ie purchase/sale for the price $S_t^i$ possible at any time.\\
	
	$S^0\dots$ ''numeraire'' has a special role: describes interest rate of \emph{not} in $(S^1,..,S^d)$ invested capital; is mostly considered to be \emph{risk-free}.
\end{enumerate}

\begin{definition}[Finance market model]
	A \begriff{finance market model} (FMM) with a time axis $I$ is given by
	\begin{enumerate}
		\item a probability space $(\O, \F,\P)$ with percolation $(F_t)_{t\in I}$
		\item an adapted to $(F_t)_{t \in I}$, $R^{d+1}$-valued stochastic process $S_t = (S^0_t, S_t^1, \dots, S^d_t),t \in I$
	\end{enumerate} 
\end{definition}

\begin{*example}[\person{Cox}-\person{Rubinstein} (CRR)-model (discrete-time)]
	\begin{itemize}
		\item $S^0_n = (1+r)^n$, meaning interest at a constant rate $r$
		\item $S^1_n = S_0^1 \prod_{k=1}^n(1+Ru)$, wobei $(R_1, R_2, \dots)$ independent random variables with two possible values $a < b$\\
		Image: '' ``recombined tree '' with events $\omega$ corresponding paths in the tree
	\end{itemize}
\end{*example}
\begin{*example}[\person{Block}-\person{Scholes}-modell (continious-time)]
	\begin{itemize}
		\item $S^0_t = e^{rt}$, meaning interest at a constant rate $r$
		\item $S_t^1 = S_0^1\cdot \exp((\mu - \frac{\sigma^2}{2}t + \sigma\beta_t) \mit \mu \in \R, \sigma > 0, S^1_0 >0$ und $\beta_t$ 
		corresponds to Brownian motion(stochastic process in continuous time) and $\mu - \frac{\omega^2}{2}$ corresponds to trend component
	\end{itemize}
	Image: Exchange curve = $S_t(\omega)$, wherein time-continuous model for infinite probability space
\end{*example}
%TODO translate
\section{Anleihen und grundeliegende Beispiele für Derivate}
Hier betrachten wir immer nur ein Basisgut $S_t = S^1_t$
\begin{enumerate}
	\item \begriff{Anleihe}(\begriff{bond}): (genauer: Null-Coupon-Anleihe [zero-coupon-bond]) Der \begriff{Emittent} (Herausgeber) einer Anleihe mit Endfälligkeit $T$ [maturity] garantiert dem Käufer zum Zeitpunkt $T$ den Betrag $N$ (EUR/USD/...) zu zahlen.\\
	Typische Emittenten:
	\begin{itemize}
		\item Staaten [government bond]
		\item Unternehmen (als Alternative zur Kreditaufnahme)
	\end{itemize}
	Nach Emission werden Anleihen auf den Sekundärmarkt weiterverkauft, d.h. liquide gehandelte Wertpapiere\\
	Preis bei Emission: $B(0,T)$\\
	Preis bei Weiterverkauf zum Zeitpunkt $t \le T\colon B(t,T)$\\
	Wir normieren stets $N=1 \implies B(T,T) =1$\\
	Anleihen von West/Nord/Mitteleuropäischen Staaten + USA/Kananda werden als risikolos betrachtet (sichere Zahlung).\\
	Sonst: Kreditrisiko\\
	Risikofreie Anleihen können als Numerale $S^0_t = B(t,T)$ genutzt werden\\
	Bild: kann ich gerade nicht beschreiben :/ \\
	\item \begriff{Terminvertrag} [forward contract]\\
	Aus Käufersicht: \emph{Vereinbarung} zu bestimmten, zukünftigen Zeitpunkt $T$ eine Einheit des Basisguts $S$ zum Preis zu kaufen (Kaufverpflichtung)\\
	Beliebt bei Rohstoffen + Elektrizität\\
	Auszahlunsprofil: $F_T = S_T - K$\\
	Bild: ``Eine Gerade mit Schnittpunkt der $x$-Achse bei $K$ und Schnittpkt der $y$-Achse bei $S_T \ge 0$, ist ja nur einer Polynom 1. Ordnung''\\
	Preis zum Zeitpunkt $t$: $F_t$
	\item \begriff{Europäische Put-/Call-Option}:
	Recht zu einem zukünftigen Zeitpunkt $T$ eine Einheit des Basisguts $S$ zum Preis $K$ zu verkaufen (Put) bzw. zu kaufen (Call) \textbf{keine (Ver-)Kaufsverpflichtung}\\
	\begin{itemize}
		\item \emph{Call}:
		\begin{align*}
		C_T := \begin{cases}
		S_T - K &\quad S_T \ge K\\
		0 &\quad S_T < K
		\end{cases} = (S_T - K)_+ %is this really a ``+'' or a t?!
		\end{align*}
		\begin{*remark}
			\begin{align*}
			X_+ &= \max(X,0)\quad X_+ - X__ = X\\
			X__ &= \min(X,0)\quad X_+ + X__ = \abs{X}
			\end{align*}
			Bild: (hockey stick function)
		\end{*remark}
		\item \emph{Put}:
		\begin{align*}
		P_t = \begin{cases}
		0 &\quad S_T \ge K\\
		K-S_T &\quad S_t < K
		\end{cases} = (K-S_T)_+
		\end{align*}
		Bild: ``inversed'' hockey stick function xD
	\end{itemize}
	\item \emph{Amerikanische Put/Call-Option}: Wie Put/Call aber mit Ausübung zu beliebigen Zeitpunkt $t \in [0,T]$\\
	Preis zum Zeitpunkt $t\colon P_t^{AM}, \; C_t^{AM}$\\
	Auszahlungsprofil zum zeitpunkt $\tau\colon (S_{\tau}-K), (K-S_{\tau})_+$\\
	Zeitpunkt $\tau$ muss im Allgemeinen als Lösung eines stochastischen Optimierungsproblems bestimmt werden (``\begriff{Optimales Stopproblem}'')
\end{enumerate}
\section{Elementare Replikations und Arbitrage-Argumente}
Was können wir (mit elementaren Mitteln) über die ``fairen'' Preise $B(t,T), F_t, C_t, P_t$ aussagen?\\
Wir verwenden:
\begin{itemize}
	\item \begriff{Replikationsprinzip}: Zwei identische zukünftige Zahlungsströme haben auch heute denselben Wert. (ein Zahlungstrom ``repliziert'' den anderen) % but what about inflation? Where comes inflation in this whole system in? 
	\item \begriff{No-Arbitage-Prinzip}: ``Ohne Kapiteleinsatz kann sicherer Gewinn ohne Verlustrisiko erzielt werden''
	\item \begriff{Arbitrage}: risikofreier Gewinn\\
	\item Schwächere Form des Replikationsprinzips:\\
	\begriff{Superpositionsprinzip}: Ist ein Zahlungsstrom in jedem Fall größer als ein anderer, so hat er auch heute den größeren Wert
	\begin{align*}
	\begin{matrix}
	\text{stark} & \text{Rep. Prinzip} & \text{eingeschränkt anwendbar}\\
	\downarrow & \text{Superrep. Prinzip} & \uparrow\\
	\text{schwach} & \text{No-Arbitrage-Prinzip} & \text{immer anwendbar}
	\end{matrix}
	\end{align*}
\end{itemize}
\begin{lemma} %1.1 fix numbering later ;)
	Für den preis $C_t$ des europäischen Calls gilt:
	\begin{align*}
	(S_t - K\cdot B(t,T))_+ \le C_t \le S_t
	\end{align*}
\end{lemma}
\begin{proof}
	\begin{itemize}
		\item \emph{untere Schranke}: Für Widerspruch $S_t - K\cdot(B(t,T))-C_t = \epsilon > 0$\\
		\begin{tabular}{l|l|l|l} % jeezzz i fuckin hate tables in latex xD, but i managed it ...
			Portofolio & Wert in $t$ & Wert in $T$, $S_t \le K$ & Wert in $T$, $S_t > K$\\
			Kaufe Call & $C_t$ & 0 & $S_T - K$\\
			Verkaufe Basisgut & $-S_t$ & $-S_T$ & $-S_T$\\
			Kaufe Anleihe & $\epsilon + K\cdot B(t,T)$ & $\frac{\epsilon}{B(t,T)}+K$ & $\frac{\epsilon}{B(t,T)} + K$\\
			$\Sigma$ & 0 & $K - S_T + \frac{\epsilon}{B(t,T)} > 0$ & $\frac{\epsilon}{B(t,T)} > 0$\\
			& keine Anfangskapital & sicherer Gewinn & sicherer Gewinn\\
		\end{tabular}\\
		$\implies$ Widerspruch zu No-Arbitrage\\
		$\implies$ $S_t - K\cdot B(t,T) \le C_t$ und Ausserdem $C_t \ge 0 \implies C_t \ge (S_t - K\cdot B(t,T))_+$
		\item \emph{obere Schranke}: UE
	\end{itemize}
\end{proof}
\begin{lemma}[Put-Call-Parität] % jeezz its 5:48 am im typing this, cant sleep ... :(
	Für Put $P_t$, Call $C_t$ mit demselben Ausübungspreis $K$ und Basisgut $S_t$ gilt
	\begin{align*}
	C_t - P_t = S_t - B(t,T)K
	\end{align*}
	Bild: need to add ..., but should be fast to do ...
\end{lemma}
\begin{proof} %TODO fix tables later, for now it works ..., make them one size for better reading ...
	mit Replikation:\\
	\begin{tabular}{l|l|l|l} % jeezzz i fuckin know now how to make tables in latex xD
		Portofolio 1 & Wert in $t$ & Wert in $T$, $S_t \le K$ & Wert in $T$, $S_t > K$\\
		Kaufe Call & $C_t$ & 0 & $S_T - K$\\
		Kaufe Anleihe & $K \cdot B(t,T)$ & $K$ & $K$\\
		Wert Portofolio 1 & $C_t + K\cdot B(t,T)$ & $K$ & $S_T$\\
	\end{tabular}\\
	\newline
	\begin{tabular}{l|l|l|l} % jeezzz i fuckin hate, but i can copy ... xD
		Portofolio 2 & Wert in $t$ & Wert in $T$, $S_t \le K$ & Wert in $T$, $S_t > K$\\
		Kaufe Put & $P_t$ & $K-S_T$ & 0\\
		Kaufe Basisgut & $S_t$ & $S_T$ & $S_T$\\
		Wert Portofolio 2 & $P_t + S_t$ & $K$ & $S_T$\\
	\end{tabular}\\
	Replikationsprinzip: $C_t + K\cdot B(t,T) = P_t + S_t$\\
	$\implies$ $C_t - P_t = S_t - K\cdot B(t,T)$
\end{proof} % 5:56 am and im done with it, puh ;) hope we can talk about it in english if you like. ;)
\section{Conditional expectation values and Martingale} %1.4
\subsection{Conditional density and conditional expected value}
Motivation: Given: Two random variables $(X,Y)$ with values in $\R^m \times \R^n$ and joint density $f_{XY}(x,y)$. From $f_{XY}$ we can derive:
\begin{itemize}
	\item $f_{Y}(y) := \int_{\R^m} f_{XY}(x,y) \d x$ with marginal distribution of $Y$
	\item $S_Y := \set{y \in \Rn \colon f_Y(y) > 0}$ carrier of $Y$ - Image?
\end{itemize}
\begin{*definition}[Conditional density of $X$ with respect to $Y$]
	Conditional density from $X$ with respect to $Y$ is defined as
	\begin{align*}
		f_{X\mid Y}(x,y) = \begin{cases}
			\frac{f_{XY}(x,y)}{f_Y(y)} &\quad y \in S_Y\\
			0 &\quad y\notin S_Y
		\end{cases}
	\end{align*}
\end{*definition}
Consider the following problem:\\
What is the best forecast from $X$ if an observation $Y = y$ is given?\\
Criteria:\\
Minimiye the quadratic distance/second moment/ $L_2$-norm.\\
Vorhersage:\\
Measurable function $g: \Rn \to \R^m \mit y \mapsto g(y)$, meaning,.
\begin{align*}
	\min\set{\E[(X-g(Y))]^2 \colon g \text{ messbar } \R^n \to \R^m} \tag{min-1}\label{eq_min_1}
\end{align*}
\begin{proposition} %1.3
	When $(X,Y)$ have a joint density with $\E[\abs{X}^2] < \infty$, then \eqref{eq_min_1} is going to be minimized through the conditional expected value
	\begin{align*}
		g(y) = \E[X\mid Y=y] := \int_{\R^m} x f_{X\mid Y}(x,y)\d x
	\end{align*}
	(where $\E[X\mid Y=y]$ ``expected value of $X$ conditioned on $Y=y$'')
\end{proposition}
In general, it holds:
\begin{theorem} %1.4
	Let $(X,Y)$ be random variables with joint density on$\R^m \times \Rn$, $h: \R^m \to \R^n$ measurable with $\E[h(X,y)^2]$. Then that is going to be minimisation problem
	\begin{align*}
		\min\set{\E[(h(X,Y) - g(y))^2]} \quad g\text{measurable from $\Rn$ towards $\R$}
		\intertext{solved through}
		g(y) = \E[h(X,Y) \mid Y=y] = \int_{\R^m} h(X,Y)f_{X\mid Y}(x,y) \d x
	\end{align*}
\end{theorem}
\begin{proof}[only proposition, the Theorem is analogous, for $n=1$]
	Set $g(y) = \int_{\R} f_{X\mid Y}(x,y) \d x$. Sei $p: \R \to \R$ arbitrary measurable function with $\E[p(y)^2] < \infty$. Set $g_{\epsilon}(y) = g(y) + \epsilon p(y)$. Minimize
	\begin{align*}
		F(\epsilon) &:= \E[(X-g_{\epsilon}(y))^2] = \E[(X-g(y)-\epsilon p(y))^2]\\
		&= \E[(X-g(y))^2] - 2\epsilon\E[(X-g(y))p(y)] + \epsilon^2\E[p(y)^2]\\
		\frac{\partial F}{\partial \epsilon}(\epsilon) &= 2 \epsilon \E[p(y)^2] - 2\E[(X-g(y))p(y)]\\
		&\implies \epsilon_{\ast} :=\frac{\E[(X-g(y))p(y)]}{\E[p(y)^2]} = \frac{A}{B}
		\intertext{wobei}
		A&= \E[Xp(y)] -\E[g(y)p(y)] \\
		&= \int_{\R \times \Rn} xp(y)f_{XY}(x,y)\d x \d y - \int_{S_y}g(y)p(y)f_Y(y) = [\text{Einsetzen von $g$ + Fubini}]\\
		&= \int_{\R \times \Rn} xp(y)f_{XY}(x,y)\d x \d y - \int_{\R\times S_y} xp(y)\underbrace{f_{X\mid Y}(x,y)f_Y(y\d y)}_{=f_{XY}(x,y)} = 0
	\end{align*}
	so $\epsilon^{\ast} = 0$ independent from  $p$ $\implies g(y)$ minimizes \eqref{eq_min_1}.
\end{proof}
\begin{*example}
	Let $(X,Y)$ normaly distributed on $\R\times \R$ with
	\begin{align*}
		\mu = (\mu_x, \mu_y)^T \quad \Sigma = \begin{pmatrix}
			\sigma x^2 \rho\sigma_x \sigma_y\\
			\rho \sigma_x \sigma_y & \sigma_y^2
		\end{pmatrix} = \begin{pmatrix}
			\Var(X) & \Cov(X,Y)\\
			\Cov(X,Y) & \Var(Y)
		\end{pmatrix} \mit \rho \in [-1,1]
	\end{align*}
	Then the arbitraty density is $f_{X\mid Y}(x,y)$. ($\Sigma$ covariance matrix). Once more the density of a normaly distributed random variable with 
	\begin{align*}
		\E[X \mid Y=y] &= \mu_x + \rho \frac{\sigma_x}{\sigma_y}(y-\mu_y)\\
		\Var(X\mid Y=y) &= \sigma_x^2(1-\rho^2)
	\end{align*}
	(is ÜA!). The mapping $y \mapsto \mu_x + g(y)\frac{\sigma_x}{\sigma_y}(y-\mu_y)$ is called regression line for $X$ given $Y=y$.\\
	Image: $\mu_x,\mu_y$ are values on $x,y$-axis and the $\sigma$'s build the Triangle slope (slope is known substantially by $\rho$)\\
	For disrete random variables, i.e. when $X,Y$ accept only finitely many $\set{x_1,\dots,x_m}$ or $\set{y_1,\dots,y_m}$ annehmen then with similar considerations we obtain as a solution of \eqref{eq_min_1}
	\begin{align*}
		\E[X\mid Y=y_j] = \sum_{i=1}^m X_i \P(X=x_i \mid Y=y_j)
	\end{align*}
	wherein directly the conditional probabilities
	\begin{align*}
		\P(X=x_i \mid Y=y_j) = \begin{cases}
			\frac{\P(X=x_i \wedge Y=y_j)}{\P(Y=y_j)} &\quad \text{ wenn } \P(Y=y_j) > 0\\
			0 &\quad \text{ wenn } \P(Y=y_j) = 0 
		\end{cases}
	\end{align*}
\end{*example}
\subsection{Conditional expectation - measure theoretical access}
We consider a probability space $(\O, \F,\P)$. For random variables $X: \O \to \R$ und $p \in [1,\infty)$ we define the $L_p$-norm
\begin{align*}
	\norm{X}_p = \E[\abs{X}^p]^{1/p} = \brackets{\int_{\O} \abs{X(\omega)}^p \d \P(\omega)}^{1/p}
\end{align*}
and $L_p$-space $L_p(\O,\F,\P):= \set{X: \O \to \R\colon \F-\text{measurable}, \norm{X}_p < \infty}$. We identificate random variables which differ only at zero amounts, ie $\P(X \neq X') = 0 \implies X = X'$ (in $L_p$).\\
From measure theory it is known: (?)\\
The spaces $L_p(\O,\F,\P)$ with norm $\norm{\cdot}_p, p \in [1,\infty)$ are always \person{Banach}-spaces (linear, complete, normed vector spaces). For $p = 2$ also hilbert spaces with inner product
\begin{align*}
	\scaProd{X}{Y} = \E[XY] = \int_{\O} X(\omega)Y(\omega)\d \P(\omega)
\end{align*}
Für $\G \subseteq \F$ Unter-$\sigma$-slgebra is $L_p(\O,\F,\P) \subseteq L_p(\O,\F,\P)$ closed subspace.\\
We generalize ''prediction problem'' from the last section (1.3?)\\
Given are random variables $X$ from $L_2(\O,\F,\P)$ is $\G \subseteq \F$ Sub-$\sigma$-algebra.\\
What is the best $\G$-measurable forecast for $Y$?
\begin{align*}
	\min\set{\E[(X-G)^2] \colon G \in L_2(\O,\F,\P)} \tag{min-2}\label{eq_min_2}
\end{align*}
wobei $\E[(X-G)^2] = \norm{X-G}^2_2$.\\
From hilbert-space theory:\\
\eqref{eq_min_2} possesses a unique solution $G_{\ast} \in L_2(\F,\G,\P)$. $G_{\ast}$ is optimization (with respect to $\scaProd{\cdot}{\cdot}$) from $X \in L_2(\Omega,F,P)$ on closed subspace $L_2(\Omega,G,P)$\\
Image: maybe from Eric (Orthogonal projection on the subspace)\\
We denote the conditioned expected value $\E[X\mid \G]$ of $X$ with recpect to $\G$ with $G_{\ast}$.
\begin{theorem} %1.5
	Let $X,Y \in L_2(\O,\F,\P)$ and $\G \subseteq F$ sub-$\sigma$-algebra. Then it holds 
	\begin{enumerate}
		\item (Linearity) $\E[aX+bY] = a\E[X\mid \G] + b\E[Y\mid \G]$
		\item (Tower rule) For every further $\sigma$-algebra $\H \subseteq\G$ it holds
		\begin{align*}
			\E[E[X\mid \G \mid \H]] = \E[X\mid \H]
		\end{align*}
		\item (Pullout-Property) $\E[XZ\mid \G] = Z\E[X\mid \G]$, if $Z$ is bounded and $\G$-measurable.
		\item (Monotonicity) $X \le Y \implies \E[X\mid \G] \le \E[Y \mid \G]$
		\item ($\Delta$-Inequality) $\abs{\E[X\mid \G]} \le \E[\abs{X}\mid \G]$
		\item (Independence) $X$ independent from $G$ $\implies$ $\E[X \mid \G] = \E[X]$
		\item (trivial $\sigma$-algebra) $\G=\set{\emptyset, \O} \implies \E[X \mid \G] = \E[X]$ 
	\end{enumerate}
\end{theorem}
\begin{proof}
	(without proof, see lecture probability theory with martingales or stochastics script SS19.)
\end{proof}
\begin{*remark}
	\begin{itemize}
		\item The conditioned expectation value $\E[X\mid \G]$, which is defined for $X \in L_2(\O,\F,\P)$, can be extended by approximation on all $X\in L_1(\O,\F,\P)$. All properties from Theorem \propref{1_5_eigen_bedEW} remain the same!
		\item Let $Y$ be a random variable and $\G = \sigma(Y)$ the $\sigma$-algebra which is generated by $Y$. We write:
		\begin{align*}
		\E[X\mid Y] = \E[X \mid \sigma(Y)] \quad \sigma\text{-measurable random variables}
		\end{align*}
		\item Measure theory: \person{Doob}-\person{Dynkin}-Lemma $\implies \exists$ measurable function $g: \Rn \to \R$ such that
		\begin{align*}
		\E[X\mid Y] = g(Y)
		\end{align*}
		Where $g$ is exactly the function from \eqref{eq_min_1}.
	\end{itemize}
\end{*remark}
Summary:\\
Let $X,Y$ from $L_1(\O,\F,\R)$, $\G \subseteq \F$ sub-$\sigma$-algebra
\begin{enumerate}
	\item $\E[X\mid Y=y]$ is a measurable function $g: \Rn \to \Rn$. If the conditioned density exists, then it holds:
	\begin{align*}
		\E[X\mid Y=y] = \int_{\R^m} f_{X\mid Y} (x,y) \d x
	\end{align*}
	\item $\E[X\mid Y]$ is a $\sigma(y)$-measurable random variable, this can be represented as $g(Y)$. If the conditioned density exists, then it holds
	\begin{align*}
		\E[X\mid Y](\omega) = \int_{\Rn}xf_{X\mid Y}(x,Y(\omega))\d x
	\end{align*}
	\item $\E[X \mid \G]$ is a $\G$-measurable random variable. If $\G = \sigma(y)$ then 2) occurs.
\end{enumerate}
In the general case $\bar{\E[X\mid \cdot]}$ can be interpreted as \emph{best forecast} for $X$, given
\begin{enumerate}
	\item Pointwise observation $Y=y$
	\item Observation $Y$
	\item Information $\G$
\end{enumerate}
\subsection{Martingale}
Prototype of a ''neutral'' stochastic process, which has neither upward nor downward trend. Here only in discrete time $Z = \N_0$.
\begin{*definition}[Martingale without a percolation]
	Let $(X_n)_{n\in \N_0}$ be a stochastic process. If it holds
	\begin{enumerate}
		\item $\E[\abs{X_n}] < \infty$ $\forall n \in \N$
		\item $\E[X_{n+1},\dots, X_n] = X_n$ $\forall n \in \N$
	\end{enumerate}
	then $(X_n)$ is called a \begriff{martingale}. If we define $\F_n^{\ast} = \sigma(X_1,\dots,X_n)$, then we can write 2) as
	\begin{align*}
		\E[X_{n+1} \mid \F_n^{\ast}] = X_n \quad \forall n \in \N
	\end{align*}
\end{*definition}
Interpretation:\\
\begin{itemize}
	\item The best forecast for a future value $X_{n+1}$, based on the past $\sigma(X_1,\dots,X_n)$ is the current value $X_n$.
	\item From the tower tule it follows
	\begin{align*}
		\E[X_{n+k} \mid \F_n^{\ast}] &= X_n \quad n,k \in \N_0
		\intertext{since}
		\E[X_{n+k}\mid\F_n^{\ast}] &= \E[\E[X_{n+k}\mid \F_{n+k-1}\mid \F_n^{\ast}]] = \E[X_{n+k-1}\mid \F_n^{\ast}] = (k\text{-mal}) = X_n
	\end{align*}
\end{itemize}
It can be extended from $(\F_{n})_{n \in \N}$ to arbitrary percolations $(\F_n)_{n \in \N_0}$.
\begin{*definition}[Martingale with percolation]
	Let $(X_n)_{n \in \N_0}$ be a stochastic process, which is adapted to a percolation $(\F_n)_{n \in \N_0}$. If it holds
	\begin{enumerate}
		\item $\E[\abs{X_n}] < \infty$ $\forall n \in \N_0$
		\item $\E[X_{n+1} \mid \F_n] = X_n$ $\forall n \in \N_0$
	\end{enumerate}
	then $(X_n)_{n \in \N_0}$ is called a \begriff{martingal with respect to percolation} $(\F_n)_{n \in \N_0}$
\end{*definition}
Interpretation:\\
The best forecast for future values $X_{n+1}$, based on the available information $\F_n$ is the current value $X_n$.
\begin{*definition}[Supermatringale, Submartingale]
	In in 2) instead of ``$=$'' the inequality $\le \oder \ge$ holds, then $(X_n)_{n \in \N}$ is called a \begriff{Supermartingale} or a \begriff{Submartingale}.
\end{*definition}
First observation:\\
\begin{itemize}
	\item $X$ Martingale $\implies \E[X_n] = X_0$, i.e. $n \mapsto \E[X_n]$ is constant.\\
	Begründung:
	\begin{align*}
		\E[X_{n+1} \mid \F_n] = X_n \implies \E[\E[X_{n+1}\mid \F_n]] = \E[X_n] = \E[X_{n+1}] \implies (n\text{-times aplied} \E[X_n] = X_0)
	\end{align*}
	Image: expected value is constant, but not a martingale.
	\item $X$ Submartingale $\implies n \mapsto \E[X_n]$ is monotone increasing
	\item $X$ Supermartingale $\implies n \mapsto \E[X_n]$ is monotone decreasing
\end{itemize}
In order to remember the difference between super and submartingale, here's a little help: \\
''Life is a supermartingale, expectations fall with time.''
\begin{*example}
	\begin{itemize}
		\item Let $(Y_n)_{n\in \N}$ be independent random vriables in $L_1(\O,\F,\P)$ mit $\E[Y_n] = 0$. Define $X_n := \sum_{k=1}^n Y_k \mit X_0 = 0$. Then $(X_n)_{n \in \N_0}$ is a martingale, since
		\begin{enumerate}
			\item $\E[\abs{X_n}] \le \sum_{k=1}^n \E[\abs{Y_k}] < \infty \quad \forall n \in \N$ \checkmark
			\item
			\begin{align*}
				\E[X_{n+1} \mid \F_n^{\ast}] &= \E[Y_{n+1} + X_n \mid \F_n^{\ast}]\\
				&= \E[Y_{n+1} \mid \F_n^{\ast}] = \E[X_n \mid \F_n^{\ast}] \quad (\text{ tower und $\F_n^{\ast}$-measurable})\\
				&= \underbrace{\E[Y_{n+1}]}_{=0} + X_n = X_n \checkmark
			\end{align*}
		\end{enumerate}
		\item Further examples are to be found on the first exercise sheet!
	\end{itemize}
\end{*example}
\begin{*definition}[predictable]
	Let $(\F_n)_{n\in \N_0}$ be a percolation. A stochastic process $(X_n)_{n \in \N}$ is called \begriff{predictable} with respect to $(\F_n)_{n \in \N_0}$, if it holds:
	\begin{align*}
		H_n \text{ is } \F_{n-1}\text{-measurable} \quad \forall n \in \N
	\end{align*}
\end{*definition}
\begin{*remark}
	Stronger property than ''adapted''.
\end{*remark}
\begin{*definition}[discrete stochastic integral]
	Let $X$ be adapted and $H$ a predictable stochastical process with respect to $(\F_n)_{n \in \N}$. Then
	\begin{align*}
		(H \bigcdot X)_n := \sum_{k=1}^n H_k (X_k - X_{k-1}) \tag{$\ast$}\label{eq_pred_stoch_process}
	\end{align*}
	is called a \begriff{discrete stochastic integral} of $H$ with respect to $X$.
\end{*definition}
\begin{*remark}
	Sums \eqref{eq_pred_stoch_process} are in the analysis called \person{Riemann}-\person{Stieltjes}-summs. They are used for constructions of the RS-integral $\int h \d \rho$.
\end{*remark}
\begin{*definition}[locally bounded]
	A stochastic process $(H_n)_{n \in \N}$ is called \begriff{locally bounded}, if there exists a (defined) sequence $c_ \in \R_{\ge 0}$  
	such that
	\begin{align*}
		\abs{H_n} \le c_n \text{ a.s. } \quad \forall n \in \N
	\end{align*}
\end{*definition}
\begin{theorem}
	Let $X$ be adapted stochastic process (with respect to percolation $(\F_n)_{n \in \N}$). Then the following statements are equivalent:
	\begin{enumerate}
		\item $X$ is a martingale
		\item $(H \bigcdot X)$ is a martingale for all locally bounded, predictable $(H_n)_{n \in N}$
	\end{enumerate}
	That means: the stochastic integral obrains the martingale-property.
\end{theorem}
\begin{proof}
	8.11.2019!
\end{proof}
\begin{*remark}
	The random variable $H$ is later going to be the investment strategy. 
\end{*remark}