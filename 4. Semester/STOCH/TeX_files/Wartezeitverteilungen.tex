\section{Wartezeitverteilungen}

\emph{Negative Binomialverteilung}:\\
Wir wiederholen ein Bernoulliexperiment mit Erfolgswahrscheinlichkeit $p \in [0,1]$ unendlich oft. Gesucht ist die Anzahl der Misserfolge bis zum $r$-ten Erfolg, $r \in \N$. Ein passender Ergebnisraum ist $\O = \N_0$. Für Modellierung ist es jedoch leichter in jedem Versuch erfolgt (``1'') oder Misserfolg (``0'') festzuhalten und $i$ mit dem unendlichen Produktmaß des Bernoullimaßes auf $\set{0,1}^{\N}$ zu arbeiten.\\
Als Zufallsvariable
\begin{align*}
	X_r : \set{0,1}^{\N} \to \O
\end{align*}
welche die Anzahl der Misserfolge bis zum $r$-ten Erfolg darstellt, setze
\begin{align*}
	X_r (\omega) &= \min \set{\sum_{i=1}^k \omega_i = r} = r.
	\intertext{Dann}
	\P(X_r = k) &= \sum_{\substack{\omega \in \set{0,1}^{\N}\\ X_r(\omega) = k}} \prod_{i=1}^{\infty} \rho(\omega_i)
	\intertext{mit $\rho(0) = 1-p, \rho(1) = 1$ (Zähldichte der Bernoulliverteilung), also}
	\P(X_r = k) &= \binom{r+k-1}{k} (1-p)^k p^r \quad r \in \N_0.
\end{align*}
\begin{definition}[negative Binomialverteilung, geometrische Verteilung]
	Sei $p \in[0,1]$ und $r \in \N$, dann heißt die Verteilung auf $\N_0$ mit Zähldichte
	\begin{align*}
		\rho(k) = \binom{r+k-1}{k} p^r (1-p)^k
	\end{align*}
	die \begriff{negative Binomialverteilung} mit Parametern $(r,p)$. Schreibe $\negBin(r,p)$. Im Fall $r = 1$ nennen wir die Verteilung mit Zähldichte
	\begin{align*}
		\rho(k) = p(1-p)^k \quad k \in \N_0
	\end{align*}
	\begriff{geometrische Verteilung} mit Parametern $p$. Schreibe $\Geom(p)$.
\end{definition}

\subsection{Exponential- und Gammaverteilung}

\begin{enumerate}
	\item \emph{Ziel:} Modelliere die Wartezeit auf $r$ Ereignisse in kontinuierlicher Zeit.
	\item \emph{Wähle:} $(\Omega, \F) = (\R_+, \borel(R_+))$
	\item \emph{Annahmen:} 
	\begin{itemize}
		\item Jedes Ereignis geschieht zu einer zufälligen Zeit
		\item Die Anzahl der Ereignisse bis zur Zeit $t$ sei $\Pois(\lambda t)$ verteilt.
	\end{itemize}
	Die zweite Annahme macht Sinn, denn
	\begin{itemize}
		\item Poissonverteilung ist Modell für Anzahl seltener Ereignisse
		\item Nach Beispiel 3.26:
		\begin{align*}
			\Pois(\lambda t) \star \Pois(\lambda s) = \Pois(\lambda(t+s)) 
		\end{align*}
		Die Linearität des Parameters entspricht also einer Stationaritätsvorrausetzung:\\
		Modelliert
		\begin{align*}
			X\sim\Pois(\lambda t) \text{ die Ereignisse in } (0,t],\\
			Y\sim\Pois(\lambda s) \text{ die Ereignisse in } (t,t+s]
			\intertext{so modelliert}
			X+Y \sim \Pois(\lambda (t+s)) \text{ die Ereignisse in } (0,t+s].
		\end{align*}
	\end{itemize}
\end{enumerate}
Unter diesen Annahmen folgt für die Wahrscheinlichkeit in $(0,t]$ mindestens $r$ Ereignisse zu beobachten
\begin{align*}
	\P ((0,t)) &= 1-\sum_{k=0}^{r-1} \underbrace{\exp(-\lambda t) \frac{(\lambda t)^k}{k!}}_{\text{Zähldichte }\Pois(\lambda t)\text{ in }t}  \\
	\frac{\d}{\d t} &\brackets{1- \sum_{k=0}^{r-1} \exp(-\lambda t) \frac{(\lambda t)^k}{k!}}  \\
	&= - (-\lambda) e^{-\lambda t} \sum_{k=0}^{r-1} \frac{(\lambda t)^k}{k!} - e^{-\lambda t} \sum_{k=0}^{r-1} \frac{\lambda^k t^{k-1}}{(k-1)!}  \\
	&= e^{-\lambda t} \left(\sum_{k=0}^{r-1} \frac{\lambda^k t^{k-1}}{k!} - \sum_{l=0}^{r-1} \frac{\lambda^k t^{l-1}}{(l-1)!}\right) 
\end{align*}
gilt
\begin{align*}
	\P((0,t)) = \int_{0}^t e^{-\lambda t} \frac{\lambda^r x^{r-1}}{(r-1)!} \d x.
\end{align*}

Wir definieren allgemeiner:
\begin{definition}
	Seinen $\lambda > 0, r>0$, dann heißt die Verteilung auf $(\R_+, \borel(\R_+))$ mit Dichte
	\begin{align*}
		f(x) = \frac{\lambda^r}{\Gamma(r)} x^{r-1} e^{-\lambda x},
		\intertext{wobei}
		\Gamma(r) = \int_{0}^{\infty} y^{r-1}e^{-y} \d y, r>0
	\end{align*}
	\begriff{Gammefunktion}, \begriff{Gammaverteilung} mit Parametern $\lambda,r$. Schreibe $\Gam(\lambda,r)$. Insbesondere ist $\Geom(\lambda,1)$ gerade die \begriff{Exponentialverteilung} (vgl. Bsp 17?).
\end{definition}
Die Gammaverteilung ist reproduktiv: Die Wartezeit auf $r+s$ Ereignisse entspricht der Wartezeit auf $r$ Ereignisse + $s$ (weitere) Ereignisse:
\begin{lemma} % lemma 4.4
	Seien $X \sim \Gam(\lambda,r), Y \sim \Gam(\lambda,s)$ unabhängig, dann impliziert das
	\begin{align*}
		X+Y \sim \Gam(\lambda,r+s)
	\end{align*}
\end{lemma}
\begin{proof}
	Hier nur für $r,s \in \N$, allgemein später mit \begriff{momenterzeugenden Funktionen}.\\
	Seien $\rho(x), \rho(y)$ Dichten von $X,Y$. Nach \propref{3_25} folgt
\begin{align*}
	\rho_{(X+Y)} &= \rho_X \star \rho_Y (x) = \int_{\R} \rho_X(y)\rho_Y(x-y) \d y  \\
	&= \int_{\R} \frac{\lambda^r}{\Gamma(r)} y^{r-1} e^{-\lambda y} \frac{\lambda^s}{\Gamma(s)} (x-y)^{s-1} e^{-\lambda (x-y)} \d y  \\
	&= \frac{\lambda^{r+s}}{\Gamma(r)\Gamma(s)} e^{-\lambda x} \int_0^x y^{r-1} (x-y)^{s-1} \d y  \\
	&\over{\text{part Int}}{=} \frac{\lambda^{r+s}}{\Gamma(r)\Gamma(s)} e^{-\lambda x} \brackets{\underbrace{\brackets{\frac{1}{r} y^r (x-y)^{s-1}_{y=0}}}_{=0} + \frac{s-1}{r} \int_0^x y^r (x-y)^{s-2} \diff y }  \\
	&\over{\text{Ind}}{=} \frac{\lambda{r+s}}{\Gamma(r)\Gamma(r)} e^{-\lambda x} \frac{\Gamma(r)\Gamma(s)}{\Gamma(r+s)} = \frac{\lambda^{r+s}}{\Gamma(r+s)} e^{-\lambda x} 
\end{align*}
\end{proof}
Exponentialverteilung sind zudem \begriff{gedächnislos}
\begin{lemma}
	Sei $X \sim \EXP(\lambda)$, dann gilt
	\begin{align*}
		\P(X>t) = \P(X > t+s \mid X > s) \quad t,s \ge 0 \tag{$\ast$}\label{lem:eq:gedachtnislos}
	\end{align*}
\end{lemma}
\begin{example}
	\proplbl{4_2_5}
	Eine Studentin wartet morgens eine $\EXP(\sfrac{1}{s})$ verteilte Zeit $X$ auf den Bus zur Uni. Die Wahrscheinlichkeit einer Wartezeit $\ge 5$ Minuten
	\begin{align*}
		\P(X \ge 5) = e^{-\frac{1}{s}} = e^{-1} \approx 0,37.
	\end{align*}
	An einen kalten, stürmischen Frühlingstag hat die Studentin bereits 10 Minuten gewartet. Die Wahrscheinlichkeit mindestens 5 weitere Minuten zu warten ist
	\begin{align*}
		\P8X\ge 15 \mid X > 10) = \P(X\ge 5) = e^{-1} \approx 0,37.
	\end{align*}
\end{example}
\begin{proof}[Lemma 4.4]
	\begin{align*}
		\P(X > t+s \mid X \ge s) &= \frac{\P(X> t+s, X \ge s)}{\P(X > s)}\\
		&= \frac{\P(X > t+s)}{\P(X > s)}\\
		&= \frac{e^{-\lambda(t+s)}}{e^{-\lambda t}} = e^{-\lambda t} = \P(X> t).
	\end{align*}
\end{proof}
\begin{*hint}
	Man kann sogar zeigen, dass die Exponentialverteilung die einzige absolutstetige Verteilung mit \eqref{lem:eq:gedachtnislos} ist.
\end{*hint}