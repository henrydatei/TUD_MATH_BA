\chapter{Grundbegriffe der Wahrscheinlichkeitstheorie}
\label{chapter1}
\section{Wahrscheinlichkeitsräume}

\subsection*{Ergebnisraum}

Welche der möglichen Ausgänge eines zufälligen Geschehens interessieren uns?\\
Würfeln? Augenzahl, nicht die Lage und die Fallhöhe

\begin{definition}[Ergebnisraum]
	Die Menge der relevanten Ergebnisse eines Zufallsgeschehens nennen wir \begriff{Ergebnisraum} und bezeichnen diesen mit $\Omega$.
\end{definition}

\begin{*example}
	\begin{itemize}
		\item Würfeln: $\Omega = \{1,2, \dots, 6\}$
		\item Wartezeiten: $\Omega = \real_{+} = [0, \infty)$ (überabzählbar!)
	\end{itemize}
\end{*example}

\subsection*{Ereignisse}

Oft interessieren wir uns gar nicht für das konkrete Ergenis des Zufallsexperiments, sondern nur für das Eintreten gewisser Ereignisse.
\begin{*example}
	\begin{itemize}
		\item Würfeln: Zahl ist $\ge 3$
		\item Wartezeit: Wartezeit $\le 5$ Minuten
	\end{itemize}
\end{*example}

$\longrightarrow$ Teilmenge des Ereignisraums, also Element der Potenzmenge $\mathscr{P}(\Omega)$, denen eine Wahrscheinlichkeit zugeordnet werden kann, d.h. welche \begriff{messbar} (mb) sind.

\begin{definition}[Ereignisraum, messbarer Raum]
	Sei $\Omega \neq \emptyset$ ein Ergebnisraum und $\sigF$ eine $\sigma$-Algebra auf $\Omega$, d.h. eine Familie von Teilmenge von $\Omega$, sodass
	\begin{enumerate}
		\item $\Omega \in \sigF$
		\item $A \in \sigF \Rightarrow A^C \in \sigF$
		\item $A_1, A_2, \dots \in \sigF \Rightarrow \bigcup_{i \ge 1} \in \sigF$
	\end{enumerate}
	Dann heißt $(\Omega, \sigF)$ \begriff{Ereignisraum} bzw. \begriff{messbarer Raum}.
\end{definition}

\subsection*{Wahrscheinlichkeiten}

Ordne Ereignissen Wahrscheinlichkeiten zu mittels der Abbildung

\begin{align}
	\probp: \sigF \to [0,1]\notag
\end{align}
sodass
\begin{align}
	&\text{Normierung } \probp(\Omega) = 1 \label{eq_norm}\tag{N}\\
	&\sigma\text{-Additivität für paarweise disjunkte Ereignisse} 
	A_1, A_2, \dots \in \sigF \Rightarrow \probp\brackets{\bigcup_{i \ge 1} A_i} = \sum_{i \ge 1} \probp(A_i) \label{eq_additive}\tag{A}
\end{align}
\eqref{eq_norm}, \eqref{eq_additive} und die Nichtnegativität von $\probp$ werden als \begriff{\person{Kolmogorov}sche Axiome} bezeichnet (nach Kolomogorov: Grundbegriffe der Wahrscheinlichkeitstheorie, 1933)

\begin{definition}[Wahrscheinlichkeitsmaß, Wahrscheinlichkeitsverteilung]
	Sei $(\Omega, \sigF)$ ein Ereignisraum und $\probp: \sigF \to [0,1]$ eine Abbildung mit Eigenschaften \eqref{eq_norm} und \eqref{eq_additive}. Dann heißt $\probp$ \begriff{Wahrscheinlichkeitsmaß} oder auch \begriff{Wahrscheinlichkeitsverteilung}.
\end{definition}

Aus der Definition folgen direkt:

\begin{proposition}[Rechenregeln für W-Maße]
	\proplbl{1_4}
	Sei $\probp$ ein W-Maß, Ereignisse $(\Omega, \sigF), A, B, A_1, A_2, \dots \in \sigF$. Dann gelten:
	\begin{enumerate}
		\item $\probp(\emptyset) = 0$
		\item Monotonie: $A \subseteq B \Rightarrow \probp(A) \le \probp(B)$
		\item endliche $\sigma$-Additivität: $\probp(A\cup B) + \probp(A\cap B) = \probp(A) + \probp(B)$ und insbesondere $\probp(A) + \probp(A^C) = 1$
		\item $\sigma$-Subadditivität:
		\begin{align}
			\probp\left(\bigcup_{i \ge 1} A_i\right) \le \sum_{i \ge 1} \probp(A_i)\notag
		\end{align}
		\item $\sigma$-Stetigkeit: Wenn $A_n \uparrow A$ (d.h. $A_1 \subseteq A_2 \subseteq \cdots$ und $A = \bigcup_{i=1}^{\infty} (A_i)$) oder $A_n \downarrow A$, so gilt:
		\begin{align}
			\probp(A_n) \longrightarrow \probp(A), n \to \infty \notag
		\end{align}
	\end{enumerate}
\end{proposition}

\begin{proof}
	In der Vorlesung wurde auf Schilling MINT Satz 3.3 verwiesen. Ausserdem gab es dazu Präsenzübung 1.3. Der folgende Beweis wurde ergänzt.\\
	Beweise erst Aussage: $A\cap B = \emptyset \Longrightarrow \probp(A \uplus B) = \probp(A) + \probp(B)$.\\ %TODO add reference for the claim.
	Es kann $\sigma$-Additivität verwendet werden, indem ``fehlende'' Mengen durch $\emptyset$ ergänzt werden:
	\begin{align}
		\probp(A \uplus B) = \probp(A \uplus B \uplus \emptyset \uplus \emptyset \dots) = \probp(A) + \probp(B) + \probp(\emptyset) + \dots = \probp(A) + \probp(B),\notag
	\end{align}
	wobei Maßeigenschaften verwendet werden.
	\begin{enumerate}
		\item Definition des Maßes.
		\item Da $A \subseteq B$ ist auch $B = A \uplus (B \setminus A) = A \uplus (B \setminus (A \cap B))$. Wende wieder Aussage von oben an, damit folgt
		\begin{align}
			\probp(B) = \probp(A \uplus (B \setminus A)) = \probp(A) + \probp(B \setminus A) \ge \probp(A) \label{eq_1_1_4}\tag{*}
		\end{align}
		\item Zerlege $A \cup B$ geschickt, dann sieht man mit oben gezeigter Aussage und \eqref{eq_1_1_4}
		\begin{align}
			\probp(A \cup B) + \probp(A \cap B) &= \probp(A \uplus (B \setminus (A \cap B)) + \probp(A \cap B)\notag \\
			&= \probp(A) + \probp(B \setminus (A \cap B)) + \probp(A \cap B)\notag\\
			&= \probp(A)+\probp(B).\notag	
		\end{align}
		Im letzten Schritt wurde \eqref{eq_1_1_4} verwendet.
		\item Folgt aus endlicher $\sigma$-Additivität, da $\probp\left(\bigcap_{i\ge 1} A_i \right) \ge 0$.
		\item Definiere $F_1 := A_1, F_2 := A_2 \setminus A_1, \dots, F_{i+1} := A_{i+1}\setminus A_n$. Die $F_i$ Mengen sind paarweise disjunkt und damit folgt für $m \to \infty$
		\begin{align}
			A_m = \biguplus_{i=1}^{m} F_i \Rightarrow A = \biguplus_{i=1}^{\infty} F_i = \biguplus_{i=1}^{\infty} A_i\notag
		\end{align}
		und
		\begin{align}
			\probp(A) = \probp\left( \biguplus_{i=1}^{\infty} F_i \right) = \sum_{i=1}^{\infty} \probp(F_i) = \lim\lim_{m \to \infty} \probp\left( \biguplus_{i=1}^{m} F_i \right) = \lim\lim_{m\to \infty} \probp(A_m). \notag
		\end{align}
	\end{enumerate}
\end{proof}

\begin{example}
	Für ein beliebigen Ereignisraum $(\Omega, \sigF)$ ($\Omega \neq \emptyset$) und eine beliebiges Element $\xi \in \Omega$ definiere
	\begin{align}
		\delta_{\xi}(A) := \begin{cases}
		1 & \xi \in A \\
		0 & \text{ sonst}
		\end{cases}\notag
	\end{align}
	eine (degeneriertes) W-Maß auf $(\Omega, \sigF)$, welches wir als \begriff{\person{Dirac}-Maß} oder \begriff{\person{Dirac}-Verteilung} bezeichnen.
\end{example}

\begin{example}
	Würfeln mit fairem, $6$-(gleich)seitigem Würfel mit Ergebnismenge $\Omega=\{1, \dots, 6\}$ und Ereignisraum $\sigF = \mathscr{P}(\Omega)$ setzen wir als Symmetriegründen
	\begin{align}
		\probp(A) = \frac{\# A}{6}.\notag
	\end{align}
	(Wobei $\# A$ oder auch $\vert A \vert$ die Kardinalität von $A$ ist.) Das definiert ein W-Maß.
\end{example}

\begin{example}
	\proplbl{1_1_7}
	Wartezeit an der Bushaltestelle mit Ergebnisraum $\Omega = \real_{+}$ und Ereignisraum \person{Borel}sche $\sigma$-Algebra $\borel(\real_{+}) = \sigF$. Eine mögliches W-Maß können wir dann durch
	\begin{align}
	\probp(A) = \int_{A} \lambda e^{-\lambda x} \diff x\notag %TODO set a mathoperator for dx!!!
	\end{align}
	für einen Parameter $\lambda > 0$ festlegen. (Offenbar gilt $\probp(\Omega) = 1$ und die $\sigma$-Additivität aufgrund der Additivität des Integrals.) Wir bezeichnen diese Maße als \begriff{Exponentialverteilung}. (Warum gerade dieses Maß für Wartezeiten gut geeignet ist $\nearrow$ später) %TODO add later a ref!!!
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 2nd Lecture %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{proposition}[Konstruktion von Wahrscheinlichkeitsmaßen durch Dichten]
	\proplbl{1_8}
	Sei $(\Omega, \sigF)$ ein Eriegnisraum.
	\begin{itemize}
		\item $\Omega$ abzählbar, $\sigF = \mathscr{P}(\Omega)$: Sei $\rho = (\rho(\omega))_{\omega \in \Omega}$ eine Folge in $[0,1]$ in $\sum_{\omega \in \Omega} \rho(\omega) = 1$, dann definiert
		\begin{align}
			\probp(A) = \sum_{\omega \in \Omega} \rho(\omega), A \in \sigF \notag
		\end{align}
		ein (diskretes) Wahrscheinlichkeitsmaß $\probp$ auf $(\Omega, \sigF)$. $\rho$ wird als \begriff{Zähldichte} bezeichnet.
		\item Umgekehrt definiert jedes Wahrscheinlichkeitsmaß $\probp$ auf $(\Omega, \sigF)$ definiert Folge $\rho(\omega) = \probp(\set{\omega}),\; \omega \in \Omega$ eine Folge $\rho$ mit den obigen Eigenschaften.
		\item $\Omega \subset \Rn, \sigF = \borel(\Omega)$: Sei $\rho: \Omega \to [0, \infty)$ eine Funktion, sodass
		\begin{enumerate}
			\item $\int_{\Omega} \rho(x)\diff x = 1$
			\item $\set{x \in \Omega \colon f(x) \le c} \in \borel(\Omega)$ für alle $c > 0$ 
		\end{enumerate}
		dann definiert $\rho$ ein Wahrscheinlichkeitsmaß $\probp$ auf $(\Omega, \sigF)$ durch 
		\begin{align}
		\probp(A) = \int_{A} \rho(x) \diff x = \int_{A} \rho \diff \lambda, \quad A \in \borel(\Omega).\notag
		\end{align}
		Das Integral interpretieren wir stets als Lebesgue-Integral bzw. Lebesgue-Maß $\lambda$.
		$\rho$ bezeichnet wir als \begriff{Dichte}, \begriff{Dichtefunktion}/\begriff{Wahrscheinlichkeitsdichte} von $\probp$ und nennen ein solches $\probp$ \begriff{(absolut) stetig (bzgl. denn Lebesgue-Maß)}.
	\end{itemize}
\end{proposition}

\begin{proof}
	\begin{itemize}
		\item Der diskrete Fall ist klar.
		\item Im stetigen Fall folgt die Bahuptung aus den bekannten Eigenschaften des Lebesgue-Integrals ($\nearrow$ Schilling MINT, Lemma 8.9)
	\end{itemize}
\end{proof}

\begin{*remark}
	\begin{itemize}
		\item Die eineindeutige Beziehung zwischen Dichte und Wahrscheinlichkeitsmaß überträgt sich nicht auf den stetigen Fall.
		\begin{itemize}
			\item Nicht jedes Wahrscheinlichkeitsmaß auf $(\Omega, \borel(\Omega))  \mit \Omega \subset \Rn$ besitzt eine Dichte.
			\item Zwei Dichtefunktionen definieren dasselbe Wahrscheinlichkeitsmaß, wenn sie sich nur auf einer Menge vom \person{Lebesgue}-Maß $0$ unterscheiden.
		\end{itemize}
		\item Jede auf $\Omega \subset \Rn$ definiert Dichtefunktion $\rho$ lässt sich auf ganz $\Rn$ fortsetzen durch $\rho(x) = 0\mit x \not\in \Omega$. Das erzeugte Wahrscheinlichkeitsmaß auf $(\Rn, \borel(\Omega))$ lässt mit dem Wahrscheinlichkeitsmaß auf $(\Omega, \borel(\Omega)$ identifizieren.
		\item Mittels Dirac-Maß $\delta_{x}$ können auch jedes diskrete Wahrscheinlichkeitsmaß auf $\Omega \subset \Rn$ als Wahrscheinlichkeitsmaß auf $(\Rn, \borel(\Rn))$ intepretieren
		\begin{align*}
			\probp(A) = \sum_{\omega \in A} \rho(\omega) = \int_{A} \diff \left( \sum_{\omega \in \Omega} \rho(\omega)\delta_{\omega} \right)\\
			\intertext{stetige und diskrete Wahrscheinlichkeitsmaße lassen sich kombinieren z.B.}
			\probp(A) = \frac{1}{2} \delta_{0} + \frac{1}{2} \int_{A}\indi_{[0,1]}(x)\diff x, A \in \borel(\R)
		\end{align*}
		ist ein Wahrscheinlichkeitsmaß auf $(\R, \borel(\R))$.
	\end{itemize}
\end{*remark}
Abschließend erinnern wir uns an:
\begin{proposition}[Eindeutigkeitssatz für Wahrscheinlichkeitsmaße]
	\proplbl{1_1_9}
	Sei $(\Omega, \sigF)$ Ereignisraum und $\probp$ ein Wahrscheinlichkeitsmaß auf $(\Omega, \sigF)$. 
	Sei $\sigF = \omega(\mathscr{G})$ für ein $\cap$-stabiles Erzeugendensystem $\mathscr{G} \subset \mathscr{P}(\Omega)$. 
	Dann ist $\probp$ bereits durch seine Einschränkung $\probp_{\mid \mathscr{G}}$ eindeutig bestimmt.
\end{proposition}
\begin{proof}
	$\nearrow$ Schilling MINT, Satz 4.5.
\end{proof}
Insbesondere definiert z.B.
\begin{align}
	\probp([0,a]) = \int_{0}^{a} \lambda e^{-\lambda x}\diff x = 1 - e^{-\lambda a}, a > 0 \notag
\end{align}
bereits die Exponentialverteilung aus \propref{1_1_7}.
\begin{definition}[Gleichverteilung]
    \proplbl{1_10}
	Ist $\Omega$ endlich, so heißt das Wahrscheinlichkeitsmaß mit konstanter Zähldichte $\rho(\omega) = \sfrac{1}{\abs{\Omega}}$ die \begriff{(diskrete) Gleichverteilung} auf $\Omega$ und wird mit $\Gleich(\Omega)$ notiert (U = Uniform).
	Ist $\Omega \subset \Rn$ eine Borelmenge mit Lebesgue-Maß $0 < \lambda^n(\Omega) < \infty$, so heißt das Wahrscheinlichkeitsmaß auf $(\Omega, \borel(\Omega))$ mit konstanter Dichtefunktion $\rho(x) = \sfrac{1}{\lambda^n(x)}$, die \begriff{(stetige)  Gleichverteilung} auf $\Omega$. 
	Sie wird ebenso mit $\Gleich(\Omega)$ notiert.
\end{definition}

\subsection*{Wahrscheinlichkeitsräume}

\begin{definition}[Wahrscheinlichkeitsraum]
	Ein Tripel $(\Omega, \sigF, \probp)$ mit $\Omega, \sigF$ Ereignisraum und $\probp$ Wahrscheinlichkeitsmaß auf $(\Omega, \sigF)$, nennen wir \begriff{Wahrscheinlichkeitsraum}.
\end{definition}

\section{Zufallsvariablen}

Zufallsvariablen dienen dazu von einem gegebenen Ereignisraum $(\Omega, \sigF)$ zu einem Modellausschnitt $\Omega', \sigF'$ überzugehen. 
Es handelt sich also um Abbildungen $X: \Omega \to \Omega'$.
Damit wir auch jedem Ereignis in $\sigF'$ eine Wahrscheinlichkeit zuordnen können, benötigen wir	
\begin{align}
	A' \in \sigF' \Rightarrow X^{-1} A' \in \sigF \notag		
\end{align}
d.h. $X$ sollte messbar sein.

\begin{definition}[Zufallsvariable]
	Seien $(\Omega, \sigF)$ und $(\Omega', \sigF')$ Ereignisräume. Dann heißt jede messbare Abbildung
	\begin{align}
		X: \Omega \to \Omega'\notag
	\end{align}
	Zufallsvariable (von $(\Omega, \sigF)$) nach $(\Omega', \sigF')$/ auf $(\Omega, \sigF)$ oder \begriff{Zufallselement}.
\end{definition}

\begin{example}
	\begin{enumerate}
		\item Ist $\Omega$ abzählbar und $\sigF = \pows(\Omega)$, so ist jede Abbildung $X: \Omega \to \Omega'$ messbar und damit eine Zufallsvariable.
		\item Ist $\Omega \subset \Rn$ und $\sigF = \borel(\Omega)$, so ist jede stetige Funktion $X: \Omega \to \R$ messbar und damit eine Zufallsvariable.
	\end{enumerate}
\end{example}

\begin{proposition}
	Sei $(\Omega, \sigF, \probp)$ ein Wahrscheinlichkeitsraum und $X$ eine Zufallsvariable von $(\Omega, \sigF)$ nach $(\Omega', \sigF')$. Dann definiert
	\begin{align}
		\probp'(A') := \probp\left(X^{-1}(A')\right) = \probp\left(\set{X \in A'}\right),\quad A' \in \sigF'\notag
	\end{align}
	ein Wahrscheinlichkeitsmaß auf $(\Omega', \sigF')$, welches wir als \begriff{Wahrscheinlichkeitsverteilung von X unter $\probp$} bezeichnen.
\end{proposition}

\begin{proof}
	Aufgrund der Messbarkeit von $X$ ist die Definition sinnvoll. Zudem gelten
	\begin{align*}
		\probp'(\Omega') = \probp(X^{-1}(\Omega')) = \probp(\Omega) = 1\\
		\intertext{und für $A_1', A_2', \dots \in \sigF'$ paarweise disjunkt.}
		\probp'\left( \bigcup_{i \ge 1} A_i'\right) &= \probp\left(X^{-1}\left( \bigcup_{i \ge 1} A_i' \right)\right) \\
		&= \probp\left( \bigcup_{i \ge 1} X^{-1}(A_i') \right) \\
		&= \sum_{i \ge 1} \probp(X^{-1}A_i') \\
		\intertext{da auch $X^{-1}A_1', X^{-1}A_2', \dots$ paarweise disjunkt}\\
		\probp'\left( \bigcup_{i \ge 1} A_i'\right) &= \sum_{i \ge 1} \probp'(A_i').
	\end{align*}
	Also ist $\probp'$ ein Wahrscheinlichkeitsmaß.
\end{proof}

\begin{*remark}
	\begin{itemize}
		\item Aus Gründen der Lesbarkeit schreiben wir in der Folge $\probp(X \in A) = \probp(\set{\omega \colon X(\omega) \in A})$
		\item Ist $X$ die Identität, so fallen die Begriffe Wahrscheinlichkeitsmaß und Wahrscheinlichkeitsverteilung zusammen.
		\item In der (weiterführenden) Literatur zu Wahrscheinlichkeitstheorie wird oft auf die Angabe eines zugrundeliegenden Wahrscheinlichkeitsraumes verzichtet und stattdessen eine ``Zufallsvariable mit Verteilung $\probp$ auf $\Omega$'' eingeführt.
		Gemeint ist (fast) immer $X$ als Identität auf $(\Omega, \sigF, \probp)$ mit $\sigF = \pows(\Omega) / \borel(\Omega)$.
		\item Für die Verteilung von $X$ unter $\probp$ schreibe $\probp_{X}$ und $X \sim \probp_{X}$ für die Tatsache, dass $X$ gemäß $\probp_{X}$ verteilt ist.
	\end{itemize}
\end{*remark}

\begin{definition}[identisch verteilte, reelle Zufallsvariablen]
	Zwei Zufallsvariablen sind \begriff{identisch verteilt}, wenn sie dieselbe Verteilung haben.
	Von besonderen Interesse sind für uns die Zufallsvariablen, die nach $(\R, \borel(\R))$ abbilden, sogenannte \begriff{reelle Zufallsvariablen}.
\end{definition}

Da die halboffenen Intervalle $\borel(\R)$ erzeugen, ist die Verteilung eine reelle Zufallsvariable durch die Werte $(-\infty, c], c \in \R$ eindeutig festgelegt.

\begin{definition}[(kumulative) Verteilungsfunktion von $\probp$]
	\proplbl{2_5}
	Sei $(\R, \borel(\R), \probp)$ Wahrscheinlichkeitsraum, so heißt
	\begin{align}
		F: \R \to [0,1] \text{ mit } x \mapsto \probp((-\infty, x]) \notag
	\end{align}
	\begriff{(kumulative) Verteilungsfunktion von $\probp$}.\\
	Ist $X$ eine reelle Zufallsvariable auf beliebigen Wahrscheinlichkeitsraum $(\Omega, \sigF, \probp)$, so heißt
	\begin{align}
		F: \R \to [0,1] \text{ mit } x \mapsto \probp(X \le x) = \probp(X \in (-\infty, x]) \notag
	\end{align} %TODO everything good with the X's here?
	die (kumulative) Verteilungsfunktion von $X$.
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 3rd Lecture %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{example}
	\proplbl{2_2_6}
	Sei $(\R, \borel(\R),\probp)$ mit $\probp$ Exponentialverteilung mit Parameter $\lambda > 0$
	\begin{align}
		\probp(A) = \int_{A \cap [0,\infty)}\lambda e^{-\lambda x} \diff x \quad A \in \borel(\R).\notag
	\end{align}
	Dann ist
	\begin{align}
		F(x) = \probp((-\infty, x)) = \begin{cases}
		0 &x \le 0\\
		\int_{0}^{x} \lambda e^{-\lambda y} \diff y = 1 - e^{-\lambda x} &x > 0
		\end{cases}.\notag
	\end{align}
\end{example}

\begin{center}
	\input{./tikz/bsp_exp_verteilung}
%	\caption{Verteilung zu \propref{2_2_6}} 
	%TODO fix caption?
\end{center}

\begin{example}
	Das Würfeln mit einem fairen, sechsseitigen Würfel kann mittels einer reellen Zufallsvariablen
	\begin{align}
		X: \set{1,2,\dots, 6} \to \R \mit x \mapsto x\notag
	\end{align}
	modelliert werden. Es folgt als Verteilungsfunktion
	\begin{align}
		F(x) &= \probp'(X \le x) = \probp(X^{-1}(-\infty,x]) = \probp((-\infty,x])\notag\\
		&= \frac{1}{6}\sum_{i=1}^{6} \indi_{i \le x}.\notag
	\end{align}
\end{example}

\begin{center}
	\input{./tikz/wurfelverteilung}
%	\caption{Verteilung zu \propref{2_2_6}} 
	%TODO fix caption?
\end{center}

Allgemein:

\begin{proposition}
	Ist $\probp$ ein Wahrscheinlichkeitsmaß auf $(\R, \borel(\R))$ und $F$ die zugehörige Verteilungsfunktion, so gelten
	\begin{enumerate}
		\item $F$ ist monoton wachsend
		\item $F$ ist rechtsseitig stetig
		\item $\lim\limits_{x\to -\infty} F(x) = 0$, $\lim\limits_{x\to \infty} F(x) = 1$
	\end{enumerate}
	Umgekehrt existiert zu jeder Funktion $F: \R \to [0,1]$ mit Eigenschaften 1-3 eine reelle Zufallsvariable auf $((0,1), \borel((0,1)), \Gleich((0,1))$ mit Verteilungsfunktion $F$.
	%TODO refs for the enum above 
\end{proposition}

\begin{proof}
	Ist $F$ Verteilungsfunktion, so folgt mit \propref{1_4}
	\begin{align*}
		 x \le y \Rightarrow F(x) = \probp((-\infty,x]) \overset{\propref{1_4}.3}&{\le} \probp((-\infty,y]) = F(y)\\
	\intertext{und}
		\lim_{x \searrow c} F(x) = \lim_{x \searrow c} \probp((-\infty, x]) \overset{\sigma\text{-Stetigkeit}}&{=} \probp((-\infty, c]) = F(c)\\
	\intertext{sowie}
		\lim_{x\to -\infty} F(x) &\overset{\propref{1_4}.5}{=} \probp(\emptyset) \overset{\propref{1_4}.1}{=} 0\\
		\lim_{x\to \infty} F(x) &\overset{\propref{1_4}.5}{=} \probp(\R) = 1.
	\end{align*}
	%TODO Alternative way to set the proof:
%		\begin{enumerate}
%		\item \begin{align}
%		x \le y \Rightarrow F(x) = \probp((-\infty,x]) \overset{\propref{1_4}.3}{\le} \probp((-\infty,y]) = F(y)\notag
%		\end{align}
%		\item 
%		\begin{align}
%		\lim_{x \searrow c} F(x) = \lim_{x \searrow c} \probp((-\infty, x]) \overset{\sigma\text{-Stetigkeit}}{=} \probp((-\infty, c]) = F(c)\notag
%		\end{align}
%		\item
%		\begin{align}
%		\lim_{x\to -\infty} F(x) &\overset{\propref{1_4}.5}{=} \probp(\emptyset) \overset{\propref{1_4}.1}{=} 0\notag\\
%		\lim_{x\to \infty} F(x) &\overset{\propref{1_4}.5}{=} \probp(\R) = 1.\notag\\
%		\end{align}
%	\end{enumerate}
	Umgekehrt wähle
	\begin{align}
		X(u) := \inf\set{x \in \R \colon F(x) \ge u}, \quad u \in (0,1)\notag
	\end{align}
	Dann ist $X$ eine ``linksseitige Inverse'' von $F$ (auch \begriff{Quantilfunktion} / \begriff{verallgemeinerte Inverse}).
	Wegen 3 gilt:
	\begin{align}
		-\infty < X(u) < \infty\notag
	\end{align}
	und zudem
	\begin{align}
		\set{X \le x} = (0, F(x)) \cap (0,1) \in \borel((0,1)).\notag
	\end{align}
	Da diese halboffene Mengen ein Erzeugendensystem von $\borel(\R)$ bilden, folgt bereits die Messbarkeit von $X$, also ist $X$ eine ZV. Insbesondere hat die Menge $\set{X \le x}$ gerade \person{Lebesgue}-Maß $F(x)$ und damit hat $X$ die Verteilungsfunktion $F$.
\end{proof}

\begin{conclusion}
	Ist $\probp$ Wahrscheinlichkeitsmaß auf $(\R, \borel(\R))$ und $F$ die zugehörige Verteilungsfunktion. Dann besitzt $\probp$ genau eine Dichtefunktion $\rho$, wenn $F$ stetig differenzierbar ist, denn dann gelten
	\begin{align}
		F(x) = \int_{-\infty}^{x} \rho(x) \diff x, \bzw \rho(x) = F'(x)\notag
	\end{align}
\end{conclusion}

\begin{proof}
	Folgt aus \propref{1_8}, der \propref{2_5} der Verteilungsfunktion und dem Eindeutigkeitssatz \propref{1_9}.
\end{proof}